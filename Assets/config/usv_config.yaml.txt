behaviors:
  USVNav:  # 需与Behavior Parameters中的Behavior Name完全一致
    trainer_type: ppo
    hyperparameters:
      batch_size: 128  # 增大批次大小，适配局部避障的高维状态输入
      learning_rate: 2e-4  # 降低学习率，避免模型震荡（局部避障决策更复杂）
      learning_rate_schedule: linear  # 线性衰减学习率，后期稳定收敛
      beta: 0.02  # 增大熵权重，鼓励模型探索避障策略
      epsilon: 0.15  # 减小clip范围，提高策略稳定性
      lambd: 0.95  # 保留原时序差分系数
      num_epoch: 4  # 增加训练轮次，确保高维特征充分学习
    network_settings:
      normalize: true  # 保留状态归一化，提升训练稳定性
      hidden_units: 256  # 增大隐藏层神经元数量，适配局部避障的复杂特征
      num_layers: 3  # 增加网络层数，提升特征提取能力
      activation_function: relu  # 使用ReLU激活函数，避免梯度消失
    reward_signals:
      extrinsic:
        gamma: 0.98  # 降低折扣因子，更关注短期避障奖励（原0.99）
        strength: 1.2  # 提升外部奖励权重，强化避障与路径跟踪的反馈
    # 局部避障适配参数
    max_steps: 800000  # 延长训练步数，确保模型学习全局-局部切换逻辑
    time_horizon: 128  # 延长时间步长，捕捉避障过程的时序依赖
    summary_freq: 10000  # 每10000步输出训练日志，便于监控避障性能
    keep_checkpoints: 5  # 保留5个检查点，方便回滚最优模型
    checkpoint_interval: 50000  # 每50000步保存检查点